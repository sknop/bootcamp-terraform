---
all:
  vars:
    ansible_connection: ssh
    ansible_user: ubuntu
    ansible_become: true

    region: emea
    domain: "bootcamp-{{region}}.confluent.io"

    jmxexporter_enabled: true
    jmxexporter_version: 1.5.0
    jmxexporter_jar_url: "https://github.com/prometheus/jmx_exporter/releases/download/{{jmxexporter_version}}/jmx_prometheus_javaagent-{{jmxexporter_version}}.jar"
    jmxexporter_jar_url_force: true

    deployment_strategy: parallel # instead of rolling

    ssl_enabled: true
    ssl_provided_keystore_and_truststore: true
    ssl_keystore_filepath: "/home/ubuntu/ssl/{{inventory_hostname}}-keystore.jks"
    ssl_keystore_key_password: changeme
    ssl_keystore_store_password: changeme
    ssl_truststore_filepath: "/home/ubuntu/ssl/kafka-truststore.jks"
    ssl_truststore_password: changeme
    ssl_truststore_ca_cert_alias: root-ca

    kafka_controller_sasl_protocol: kerberos
    sasl_protocol: kerberos

    kafka_connect_confluent_hub_plugins:
      - confluentinc/kafka-connect-oracle-cdc:latest
      - debezium/debezium-connector-mysql:latest
      - debezium/debezium-connector-postgresql:latest

    kafka_connect_custom_properties:
      key.converter: io.confluent.connect.avro.AvroConverter
      key.converter.schema.registry.url: "{{schema_registry_url}}"
      key.converter.enhanced.avro.schema.support: true

      value.converter: io.confluent.connect.avro.AvroConverter
      value.converter.schema.registry.url: "{{schema_registry_url}}"
      value.converter.enhanced.avro.schema.support: true

      key.converter.basic.auth.credentials.source: USER_INFO
      key.converter.basic.auth.user.info: 'alice:alice-secret'

      value.converter.basic.auth.credentials.source: USER_INFO
      value.converter.basic.auth.user.info: 'alice:alice-secret'

      key.converter.schema.registry.ssl.truststore.location: "{{kafka_connect_truststore_path}}"
      key.converter.schema.registry.ssl.truststore.password: "{{kafka_connect_truststore_storepass}}"
      key.converter.schema.registry.ssl.keystore.location: "{{kafka_connect_keystore_path}}"
      key.converter.schema.registry.ssl.keystore.password: "{{kafka_connect_keystore_storepass}}"
      key.converter.schema.registry.ssl.key.password: "{{kafka_connect_keystore_storepass}}"

      value.converter.schema.registry.ssl.truststore.location: "{{kafka_connect_truststore_path}}"
      value.converter.schema.registry.ssl.truststore.password: "{{kafka_connect_truststore_storepass}}"
      value.converter.schema.registry.ssl.keystore.location: "{{kafka_connect_keystore_path}}"
      value.converter.schema.registry.ssl.keystore.password: "{{kafka_connect_keystore_storepass}}"
      value.converter.schema.registry.ssl.key.password: "{{kafka_connect_keystore_storepass}}"

      topic.creation.enable: true
    #
    # Kerberos settings
    #
    kerberos_configure: true
    kerberos:
      realm: "BOOTCAMP-{{region | upper}}.CONFLUENT.IO"
      kdc_hostname: "samba.bootcamp-{{region}}.confluent.io"
      admin_hostname: "samba.bootcamp-{{region}}.confluent.io"
      canonicalize: false
      # sasl_protocol: kerberos

    sasl_scram_users:
      alice:
        principal: alice
        password: alice-secret
      charlie:
        principal: charlie
        password: charlie-secret

    kafka_controller_kerberos_keytab_path: "/home/ubuntu/kerberos/controller-{{inventory_hostname_short}}.keytab"
    kafka_controller_kerberos_principal: "kafka/{{inventory_hostname}}@{{kerberos.realm | upper}}"
    kafka_broker_kerberos_keytab_path: "/home/ubuntu/kerberos/kafka-{{inventory_hostname_short}}.keytab"
    kafka_broker_kerberos_principal: "kafka/{{inventory_hostname}}@{{kerberos.realm | upper}}"
    schema_registry_kerberos_keytab_path: "/home/ubuntu/kerberos/schema-registry-{{inventory_hostname_short}}.keytab"
    schema_registry_kerberos_principal: "schema-registry/{{inventory_hostname}}@{{kerberos.realm | upper}}"
    kafka_rest_kerberos_keytab_path: "/home/ubuntu/kerberos/rest-{{inventory_hostname_short}}.keytab"
    kafka_rest_kerberos_principal: "rest/{{inventory_hostname}}@{{kerberos.realm | upper}}"
    kafka_connect_kerberos_keytab_path: "/home/ubuntu/kerberos/kafka-connect-{{inventory_hostname_short}}.keytab"
    kafka_connect_kerberos_principal: "kafka-connect/{{inventory_hostname}}@{{kerberos.realm | upper}}"
    ksql_kerberos_keytab_path: "/home/ubuntu/kerberos/ksqldb-{{inventory_hostname_short}}.keytab"
    ksql_kerberos_principal: "ksqldb/{{inventory_hostname}}@{{kerberos.realm | upper}}"
    control_center_next_gen_kerberos_keytab_path: "/home/ubuntu/kerberos/control-center-{{inventory_hostname_short}}.keytab"
    control_center_next_gen_kerberos_principal: "control-center/{{inventory_hostname}}@{{kerberos.realm | upper}}"

    # RBAC settings
    #
    rbac_enabled: true
    rbac_component_additional_system_admins: [ alice ]
    mds_super_user: mds
    mds_super_user_password: mds-secret
    kafka_controller_ldap_user: kafka
    kafka_controller_ldap_password: kafka-secret
    kafka_broker_ldap_user: kafka
    kafka_broker_ldap_password: kafka-secret
    schema_registry_ldap_user: schemaregistry
    schema_registry_ldap_password: schema-secret
    kafka_connect_ldap_user: connect
    kafka_connect_ldap_password: connect-secret
    ksql_ldap_user: ksql
    ksql_ldap_password: ksql-secret
    kafka_rest_ldap_user: rest
    kafka_rest_ldap_password: rest-secret
    control_center_next_gen_ldap_user: controlcenter
    control_center_next_gen_ldap_password: c3-secret

    # mTLS settings for mTLS RBAC
    #

    mds_ssl_client_authentication: requested  # <required/requested/none>
    ssl_mutual_auth_enabled: true
    ssl_client_authentication: requested  # <required/requested/none>
    # Sets mtls on kafka broker listeners, and also acts as default value for other components kafka_controller_ssl_client_authentication, schema_registry_ssl_client_authentication, kafka_rest_ssl_client_authentication, kafka_connect_ssl_client_authentication, kafka_connect_replicator_ssl_client_authentication
    kafka_controller_ssl_mutual_auth_enabled: true
    kafka_controller_ssl_client_authentication: requested
    schema_registry_ssl_mutual_auth_enabled: true
    schema_registry_ssl_client_authentication: requested
    kafka_rest_ssl_mutual_auth_enabled: true
    kafka_rest_ssl_client_authentication: requested
    kafka_connect_ssl_mutual_auth_enabled: true
    kafka_connect_ssl_client_authentication: requested
    kafka_connect_replicator_ssl_mutual_auth_enabled: true
    kafka_connect_replicator_ssl_client_authentication: requested
    # These will all turn on due ssl_client_authentication. So we can set any of them to none and false if we dont want that component to enforce ssl client authentication(mTLS) on its clients.
    # For example to turn off mTLS on kafka connect we can use
    # kafka_connect_ssl_mutual_auth_enabled: false
    # kafka_connect_ssl_client_authentication: none

    # These variables will make CP component to MDS communication over mTLS. If not set then CP component to MDS communication would be running over LDAP+mTLS. It is our choice to enable them
    kafka_broker_rest_proxy_mds_cert_auth_only: true
    schema_registry_mds_cert_auth_only: true
    kafka_connect_mds_cert_auth_only: true
    kafka_rest_mds_cert_auth_only: true
    control_center_mds_cert_auth_only: true

    # List of super user principals who can get an impersonation token on behalf of other users. We should add broker, rest proxy, schema registry and connect principals here.
    # The Principal which is used for CP component to talk to MDS. Here that is cert principal.
    # Needed for principal propagation for Rest Proxy and Control Center to work.
    # To extract dn from cert check use openssl x509 -noout -subject -nameopt RFC2253 -in <cert>
    # using this the dn would be something like 'C=US,ST=Ca,L=PaloAlto,O=CONFLUENT,OU=TEST,CN=kafka_broker'
    # Then applying the principal mapping rules it would give the principal kafka_broker
    impersonation_super_users:
      - 'kafka'
      - 'kafka-rest'
      - 'schema-registry'
      - 'kafka-connect'

    # Optional Config
    # These users cant be impersonated by impersonation_super_users. Typically one might want to add super users here to stop any other user from impersonating it
    impersonation_protected_users:
      - 'super_user'

    # This defines principal mapping rules. Optional to define.
    # But if we want the certificate CN to get modified while defining the principal then we should define them now.
    # They should remain the same for inter broker communication to work seamlessly
    principal_mapping_rules:
      - "RULE:.*CN=([a-zA-Z0-9-_]*).*$/$1/"
      - "DEFAULT"

    # The following variables are to switch CP component to Kafka communication from internal listener(running oauthbearer+mtls) to mtls only.
    # Not a mandatory step
    schema_registry_kafka_listener_name: mtls
    kafka_connect_kafka_listener_name: mtls
    kafka_rest_kafka_listener_name: mtls
    control_center_kafka_listener_name: mtls

    kafka_broker_custom_listeners:
      broker:
        name: BROKER
        port: 9091
        ssl_enabled: true
        ssl_mutual_auth_enabled: false
        sasl_protocol: kerberos
      client_listener:
        name: CLIENT
        port: 9093
        ssl_enabled: true
        ssl_mutual_auth_enabled: true
        sasl_protocol: none
      scram_listener:
        name: SCRAM
        port: 9094
        ssl_enabled: true
        ssl_mutual_auth_enabled: false
        sasl_protocol: scram
      ldap_listener:
        name: LDAP
        port: 9095
        ssl_enabled: true
        ssl_mutual_auth_enabled: false
        sasl_protocol: plain
      mtls: # creating a new mTLS only listener
        name: MTLS
        port: 9096
        ssl_enabled: true
        ssl_mutual_auth_enabled: true
        ssl_client_authentication: required
        sasl_protocol: none

    kafka_broker_custom_properties:
      ldap.java.naming.factory.initial: com.sun.jndi.ldap.LdapCtxFactory
      ldap.com.sun.jndi.ldap.read.timeout: 3000
      ldap.java.naming.provider.url: "ldaps://samba.bootcamp-{{region}}.confluent.io"
      ldap.java.naming.security.protocol: SSL
      ldap.ssl.truststore.location: "{{kafka_broker_truststore_path}}"
      ldap.ssl.truststore.password: "{{kafka_broker_truststore_storepass}}"

      ldap.java.naming.security.principal: "charlie@BOOTCAMP-{{region | upper}}.CONFLUENT.IO"
      ldap.java.naming.security.credentials: charlie-secret
      ldap.java.naming.security.authentication: simple

      ldap.user.search.base: "OU=Users,OU=Kafka,DC=BOOTCAMP-{{region | upper}},DC=CONFLUENT,DC=IO"
      ldap.search.mode: USERS
      ldap.user.name.attribute: sAMAccountName
      ldap.user.memberof.attribute: memberOf
      ldap.user.memberof.attribute.pattern: "CN=(.*),OU=Groups,OU=Kafka,DC=bootcamp-{{region}},DC=confluent,DC=io"
      ldap.user.object.class: user

      # We always forget this
      ldap.user.search.scope: 2

      confluent.license: # your license file here

      # Schema registry authentication
      confluent.basic.auth.credentials.source: USER_INFO
      confluent.basic.auth.user.info: 'alice:alice-secret'

      # Standard settings for broker
      auto.create.topics.enable: false
      default.replication.factor: 3
      min.insync.replicas: 2

      # Special callback for ldap listener
      listener.name.ldap.plain.sasl.server.callback.handler.class: io.confluent.security.auth.provider.ldap.LdapAuthenticateCallbackHandler
      # From https://docs.confluent.io/platform/current/kafka/configure-mds/mutual-tls-auth-rbac.html#principal-mapping-rules-for-ssl-listeners-extract-a-principal-from-a-certificate
      listener.name.client.ssl.principal.mapping.rules: |
        RULE:^CN=([a-zA-Z0-9-]*).*$/$1/L ,\
        DEFAULT
      listener.name.mtls.ssl.principal.mapping.rules: |
        RULE:^CN=([a-zA-Z0-9-]*).*$/$1/L ,\
        DEFAULT
